{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DO NOT CHANGE - THIS IS JUST FOR REFERENCE"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "from pyterrier.measures import RR, nDCG, MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset(\"irds:beir/fiqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the nlpaug package\n",
    "# %pip install nlpaug\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as naf\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Texts:\n",
      "['The quick 9ry)B fox &Pv1s QEQ& the lazy dog.']\n"
     ]
    }
   ],
   "source": [
    "text = 'The quick brown fox jumps over the lazy dog .'\n",
    "aug = nac.RandomCharAug(action=\"substitute\", aug_char_p=0.8)\n",
    "\n",
    "augmented_texts = aug.augment(text)\n",
    "\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Texts:\")\n",
    "print(augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to do that. Training workers is not their job - they're building software. Perhaps educational systems in the U.S. (or their students) should worry a little about getting marketable skills in exchange for their massive investment in education, rather than getting out with thousands in student debt and then complaining that they aren't qualified to do anything.\n",
      "Noisy:\n",
      "[\"I ' m not saying I don ' t Jikm the iHCa of on - the - job training too, but you can ' t expect the cUmpaIs to do XhDt. 9Iainin8 wsr1e8s is not th+sr job - 4iey ' re bui_DNng software. Per$Cps _EucaAionkl NyDte9s in the U. S. (or theWL students) vhoulu wSrDy a little abdct 9Qrting marketable suiTls in exchange for vheur maybiWe invest7kst in education, rather t3a& getting out w8Rh PhoBsaqds in studeR& djby and then cTmOpai0ing that t!Ky ar&r ' t qualified to do Dnythz%g.\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "beir/fiqa documents: 100%|██████████| 57638/57638 [01:40<00:00, 573.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Add noise to the documents\n",
    "noisy_dataset = []\n",
    "bool = False\n",
    "\n",
    "aug = nac.RandomCharAug(aug_char_p=0.3, aug_word_p=0.3, action=\"substitute\", aug_word_min=1, aug_word_max=500000)\n",
    "\n",
    "for doc in dataset.get_corpus_iter():\n",
    "    noisy_text = aug.augment(doc['text'])\n",
    "    noisy_doc = {'docno': doc['docno'], 'text': noisy_text}\n",
    "    noisy_dataset.append(noisy_doc)\n",
    "\n",
    "    if not bool:\n",
    "        print(doc['text'])\n",
    "        print(\"Noisy:\")\n",
    "        print(noisy_text)\n",
    "        bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing noisy documents - takes too long\n",
    "# from pathlib import Path\n",
    "\n",
    "# indexer = pt.IterDictIndexer(\n",
    "#     str(Path.cwd()),  # this will be ignored\n",
    "#     type=pt.index.IndexingType.MEMORY,\n",
    "# )\n",
    "# index_ref = indexer.index(noisy_dataset, fields=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the noisy documents\n",
    "# bm25 = pt.terrier.Retriever(index_ref, wmodel=\"BM25\")\n",
    "# testset = pt.get_dataset(\"irds:beir/fiqa/test\")\n",
    "# pt.Experiment(\n",
    "#     [bm25],\n",
    "#     testset.get_topics(),\n",
    "#     testset.get_qrels(),\n",
    "#     eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "beir/fiqa documents: 100%|██████████| 57638/57638 [00:25<00:00, 2280.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Indexing documents\n",
    "from pathlib import Path\n",
    "\n",
    "indexer = pt.IterDictIndexer(\n",
    "    str(Path.cwd()),  # this will be ignored\n",
    "    type=pt.index.IndexingType.MEMORY,\n",
    ")\n",
    "index_ref = indexer.index(dataset.get_corpus_iter(), fields=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query: where should i park my rainy day emergency fund\n",
      "Noisy Query: where should i park my ainy day mergency fud\n",
      "09:51:39.680 [main] WARN org.terrier.querying.ApplyTermPipeline -- The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>0.145615</td>\n",
       "      <td>0.120467</td>\n",
       "      <td>0.099014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name     RR@10   nDCG@10    AP@100\n",
       "0  TerrierRetr(BM25)  0.145615  0.120467  0.099014"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add noise to the queries\n",
    "# Load the test dataset\n",
    "testset = pt.get_dataset(\"irds:beir/fiqa/test\")\n",
    "\n",
    "# Retrieve test queries\n",
    "test_queries = testset.get_topics()\n",
    "\n",
    "# Add noise by deleting characters 10% of the time\n",
    "aug = nac.RandomCharAug(action=\"delete\", aug_char_p=0.1, spec_char=\"\")\n",
    "\n",
    "# Apply noise to queries\n",
    "noisy_queries_list = []\n",
    "for _, row in test_queries.iterrows():\n",
    "    noisy_query = aug.augment(row['query'])\n",
    "\n",
    "    if isinstance(noisy_query, list):\n",
    "        noisy_query = \" \".join(noisy_query)\n",
    "\n",
    "    noisy_queries_list.append({'qid': row['qid'], 'query': noisy_query})\n",
    "\n",
    "noisy_queries_df = pd.DataFrame(noisy_queries_list)\n",
    "noisy_queries_df[\"qid\"] = noisy_queries_df[\"qid\"].astype(str)\n",
    "\n",
    "print(\"Original Query:\", test_queries.iloc[0]['query'])\n",
    "print(\"Noisy Query:\", noisy_queries_df.iloc[0]['query'])\n",
    "\n",
    "bm25 = pt.terrier.Retriever(index_ref, wmodel=\"BM25\")\n",
    "\n",
    "# Run the experiment\n",
    "pt.Experiment(\n",
    "    [bm25],\n",
    "    noisy_queries_df,\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query: where should i park my rainy day emergency fund\n",
      "Noisy Query: yhere should i Opark my raSny day eFer8gxnc9y pfund\n",
      "09:51:54.767 [main] WARN org.terrier.querying.ApplyTermPipeline -- The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>AP@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>0.076055</td>\n",
       "      <td>0.066641</td>\n",
       "      <td>0.054936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name     RR@10   nDCG@10    AP@100\n",
       "0  TerrierRetr(BM25)  0.076055  0.066641  0.054936"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a Sequential Augmentation Pipeline (Substitution + Insert)\n",
    "# Load the test dataset\n",
    "testset = pt.get_dataset(\"irds:beir/fiqa/test\")\n",
    "\n",
    "# Retrieve test queries\n",
    "test_queries = testset.get_topics()\n",
    "\n",
    "aug = naf.Sequential([\n",
    "    nac.RandomCharAug(action=\"substitute\", aug_char_p=0.2, spec_char=\"\"),  # Substitute 20% of characters\n",
    "    nac.RandomCharAug(action=\"insert\", aug_char_p=0.2, spec_char=\"\")       # Insert characters in 20% of positions\n",
    "])\n",
    "\n",
    "# Apply noise to queries\n",
    "noisy_queries_list = []\n",
    "for _, row in test_queries.iterrows():\n",
    "    noisy_query = aug.augment(row['query'])\n",
    "\n",
    "    if isinstance(noisy_query, list):\n",
    "        noisy_query = \" \".join(noisy_query)\n",
    "\n",
    "    noisy_queries_list.append({'qid': row['qid'], 'query': noisy_query})\n",
    "\n",
    "noisy_queries_df = pd.DataFrame(noisy_queries_list)\n",
    "\n",
    "noisy_queries_df[\"qid\"] = noisy_queries_df[\"qid\"].astype(str)\n",
    "\n",
    "print(\"Original Query:\", test_queries.iloc[0]['query'])\n",
    "print(\"Noisy Query:\", noisy_queries_df.iloc[0]['query'])\n",
    "\n",
    "bm25 = pt.terrier.Retriever(index_ref, wmodel=\"BM25\")\n",
    "\n",
    "# Run the experiment\n",
    "pt.Experiment(\n",
    "    [bm25],\n",
    "    noisy_queries_df,\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyterrier_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
